{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ec57b7",
   "metadata": {},
   "source": [
    "# Importing necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdd76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4229bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assignment1_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-14c7208b451e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#importing dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'assignment1_dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assignment1_dataset'"
     ]
    }
   ],
   "source": [
    "#importing dataset\n",
    "data=pd.read_csv('Assignment1\\assignment1_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the first five lines of imported datasets\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fdb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing to check the shape of the array\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ac90d",
   "metadata": {},
   "source": [
    "# Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01552b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the multi variables\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the variables(independent(X) and dependent(Y))\n",
    "X = data[0:, 0:5]\n",
    "Y = data[:, -1].reshape(data.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into two training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091200a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#introducing a constant input, x0, whose value is always 1\n",
    "#and concatenating it with X_train and X_test variables\n",
    "X_train = np.vstack((np.ones((X_train.shape[0], )), X_train.T)).T\n",
    "X_test = np.vstack((np.ones((X_test.shape[0], )), X_test.T)).T\n",
    "\n",
    "#printing to check the shape of the X_train, Y_train, X_test and Y_test variables\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14504c7",
   "metadata": {},
   "source": [
    "# Defining train_model function to find the estimated weights and training loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model function\n",
    "def train_model(X, Y, alpha, max_epoch):\n",
    "    \n",
    "    #assigning the size of Y variable to m\n",
    "    m = Y.size\n",
    "    \n",
    "    #initializing variables for weights(w), derivative of weights(d_weight) and loss history(hist_loss)\n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    d_weight = np.zeros((X.shape[1], 1))\n",
    "    hist_loss = []\n",
    "    \n",
    "    #formula to calculate the estimated weights\n",
    "    for i in range(iteration):\n",
    "        y_bar = np.dot(X, w)        \n",
    "        y_new = (Y-y_bar)\n",
    "        j = 0\n",
    "        \n",
    "        while j < w.shape[0]:\n",
    "            k = 0\n",
    "            sum_weight = 0\n",
    "            while k < m:\n",
    "                temp_weight = 0\n",
    "                temp_weight = X[k][j] * y_new[k]\n",
    "                sum_weight = sum_weight + temp_weight\n",
    "                k = k + 1\n",
    "            d_weight[j] = (-1/m)*sum_weight\n",
    "            j = j + 1\n",
    "        \n",
    "        l = 0\n",
    "        while l < w.shape[0]:\n",
    "            w[l] = w[l] - (alpha*d_weight[l][0])\n",
    "            l = l+1\n",
    "        \n",
    "        #formula to calculate the training loss history\n",
    "        loss = (1/(2*m))*np.sum(np.square(Y - y_bar))\n",
    "        hist_loss.append(loss)\n",
    "        \n",
    "        #Displaying the training loss value for each epoch of the training loop\n",
    "        print(\"Training loss history is :\", loss, \"  iteration:   \", i)\n",
    "            \n",
    "    return w, hist_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12629208",
   "metadata": {},
   "source": [
    "# Defining the prediction function to find the predicted values for y(test) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597972f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, X):\n",
    "    yhat = np.zeros((200, 1))\n",
    "    for i in range(0,200):\n",
    "        yhat[i][0] = w[0]*X[i][0] + w[1]*X[i][1] + w[2]*X[i][2] + w[3]*X[i][3] + w[4]*X[i][4] + w[5]*X[i][5]\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331c6d0",
   "metadata": {},
   "source": [
    "# Defining loss_fn function to find the loss values for y(test) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function\n",
    "#calculate loss value with MSE & R-squared Error Measures\n",
    "def loss_fn(y, yhat):\n",
    "    m = y.size\n",
    "    \n",
    "    #calculate loss value for Mean Square Error Measure    \n",
    "    meanloss = np.square(np.subtract(y,yhat)).mean()\n",
    "    print(\"Mean Square Error Measure: \", meanloss)\n",
    "    \n",
    "    #calculate SSE & SST\n",
    "    sse = np.sum(np.square(y - yhat))\n",
    "    sst = np.sum(np.square(y - ((1/(m))*np.sum(y))))\n",
    "    \n",
    "    \n",
    "    #calculate loss value for R-squared Error Measure\n",
    "    rsqloss = 1 - sse / sst\n",
    "    print(\"R-squared Error Measure: \", rsqloss)\n",
    "    return meanloss, rsqloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82a31a",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing learning rate and epoch\n",
    "iteration = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "#calling train_model function to train the train data and estimate the weights\n",
    "w, hist_loss = train_model(X_train, y_train, learning_rate, iteration)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "#Displaying the estimated weights after model training\n",
    "print(\"Estimated weights: \\n\",w)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "#calling prediction function to find the predicted y value for the test data\n",
    "yhat = prediction(w,X_test)\n",
    "\n",
    "#calling loss_fn to find the mean squared error & R-squared error\n",
    "meanloss, rsqloss = loss_fn(y_test, yhat)\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4c769",
   "metadata": {},
   "source": [
    "# Analysis of the trained model with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf939822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the training loss against epoch graph after model training\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "epoch=list(range(0,100))\n",
    "plt.xlabel(\"Epoch(number of iterations)\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.plot(epoch,hist_loss)\n",
    "print(\"The lowest cost: \" + str(np.min(hist_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the predicted y data(yhat) against the testing y data(y_test)\n",
    "\n",
    "plt.scatter(yhat,y_test)\n",
    "plt.xlabel(\"Y Test\")\n",
    "plt.ylabel(\"Y Predicted (yhat)\")\n",
    "\n",
    "#Plotting a linear line\n",
    "\n",
    "x=np.linspace(-75,100,100)\n",
    "y=x\n",
    "plt.plot(x,y,'r')\n",
    "plt.show()\n",
    "\n",
    "#Analysis of the scatter graph\n",
    "\n",
    "print(\"Mean squared error measure: \",str(meanloss))\n",
    "print(\"Mean squared error measure from trained model(optimum): \",str(hist_loss[-1]))\n",
    "print(\"Difference between predicted and optimum mean squared error: \",str(abs(meanloss-hist_loss[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce52a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
